{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d4ac02",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "cb01979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pprint\n",
    "import itertools\n",
    "\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a050c3",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "38077b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_location_json = Path('../config/FeatureLocation.json')\n",
    "chip_location_json = Path('../Label_templates/Chip_map_list.json')\n",
    "\n",
    "image_path = Path('/Volumes/krauss/Lisa/GMR/Array/250325/loc1_1/Pos0/img_000000000_Default_000.tif')\n",
    "image_path = Path('/Volumes/krauss/Callum/03_Data/17_array_testing/ethanol_full_array_test_240425_flipped/image_20250424_161414.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2139dbc",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. ☑ Load user feature location JSON file\n",
    "\n",
    "2. ☑ Calculate the scale factor and image angle using the user feature location\n",
    "\n",
    "3. ☑ Load the chip map JSON file and extract the labels location\n",
    "\n",
    "4. ☑ Calculate the scale factor and image angle using the chip map\n",
    "\n",
    "5. ☑ Rotate the image and user feature locations using calculated angle\n",
    "\n",
    "6. ☑ Load template image and scale according to the scale factor\n",
    "\n",
    "7. ☑ Find the location of the template in the image using cv2.matchTemplate\n",
    "\n",
    "8. ☑ Display the results of the template matching on the image\n",
    "\n",
    "9. ☑ Calculate some FOM values based on the template matching results\n",
    "\n",
    "10. ☐ If matching FOM is below some threshold, attempt to match with a different technigue\n",
    "\n",
    "11. ☐ Comparem matching results, if one is better, use that one\n",
    "\n",
    "12. ☐ Calculate chip map transformation to match image\n",
    "\n",
    "13. ☐ Save list of ROIs (i.e. grating locations) to a JSON file using transformation\n",
    "\n",
    "☐ Unchecked\n",
    "☑ Checked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2152e",
   "metadata": {},
   "source": [
    "## Load user feature locations from JSON file and populate 'user_chip_mapping' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "450bd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from '{file_path}'. Check the file format.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "70148129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User 'FeatureLocation.json' loaded successfully:\n",
      "{   'chip_type': 'IMECII_2',\n",
      "    'features': [   {'label': 'B-Left', 'user_location': [1320, 5022]},\n",
      "                    {'label': 'C-Left', 'user_location': [1296, 3588]},\n",
      "                    {'label': 'D-Left', 'user_location': [1254, 2178]},\n",
      "                    {'label': 'E-Left', 'user_location': [1206, 768]}]}\n"
     ]
    }
   ],
   "source": [
    "def load_user_feature_locations(file_path):\n",
    "    user_raw_data = load_json(file_path)\n",
    "    user_chip_mapping = {}\n",
    "    if user_raw_data:\n",
    "        user_chip_mapping['chip_type'] = user_raw_data.get('chip_type', None)\n",
    "        features = []\n",
    "        for feature in user_raw_data.get('features', []):\n",
    "            label_name = feature.get('label')\n",
    "            feature_location = feature.get('feature_location')\n",
    "            if label_name:\n",
    "                features.append({\n",
    "                    'label': label_name,\n",
    "                    'user_location': feature_location\n",
    "                })\n",
    "        user_chip_mapping['features'] = features\n",
    "    else:\n",
    "        print(\"[ERROR] No valid user 'FeatureLocation.json' to load.\")\n",
    "    return user_chip_mapping\n",
    "\n",
    "user_chip_mapping = load_user_feature_locations(feature_location_json)\n",
    "\n",
    "if user_chip_mapping:\n",
    "    print(\"[INFO] User 'FeatureLocation.json' loaded successfully:\")\n",
    "    pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "    pp.pprint(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdeb03",
   "metadata": {},
   "source": [
    "## Load chip map locations from JSON and update 'user_chip_map' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "221bd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User data updated successfully:\n",
      "{   'chip_type': 'IMECII_2',\n",
      "    'features': [   {   'chip_location': [-2312, 960],\n",
      "                        'label': 'B-Left',\n",
      "                        'user_location': [1320, 5022]},\n",
      "                    {   'chip_location': [-2312, -40],\n",
      "                        'label': 'C-Left',\n",
      "                        'user_location': [1296, 3588]},\n",
      "                    {   'chip_location': [-2312, -1040],\n",
      "                        'label': 'D-Left',\n",
      "                        'user_location': [1254, 2178]},\n",
      "                    {   'chip_location': [-2312, -2040],\n",
      "                        'label': 'E-Left',\n",
      "                        'user_location': [1206, 768]}]}\n"
     ]
    }
   ],
   "source": [
    "def get_type_of_chip(chip_type, all_chip_mappings):\n",
    "    for chip_mapping in all_chip_mappings:\n",
    "        chip_name_label = chip_mapping.get('chip_type', None)\n",
    "        if chip_name_label == chip_type:\n",
    "            return chip_mapping\n",
    "    return None\n",
    "\n",
    "def get_location_from_label(label, chip_mapping):\n",
    "    for chip_label in chip_mapping.get('labels'):\n",
    "        if chip_label.get('label') == label:\n",
    "            return chip_label.get('label_origin', None)\n",
    "    return None\n",
    "\n",
    "def get_user_label_locations_from_chip_map(chip_mapping, user_chip_mapping):\n",
    "    user_features = user_chip_mapping.get('features', None)\n",
    "    if user_features:\n",
    "        for idx, user_feature in enumerate(user_features):\n",
    "            label = user_feature.get('label')\n",
    "            feature_location = get_location_from_label(label, chip_mapping)\n",
    "            user_chip_mapping['features'][idx]['chip_location'] = feature_location\n",
    "        return user_chip_mapping\n",
    "    return None\n",
    "\n",
    "def load_chip_feature_locations(file_path, user_chip_mapping):\n",
    "    chip_raw_data = load_json(file_path)\n",
    "    chip_type = user_chip_mapping.get('chip_type')\n",
    "    chip_mapping = get_type_of_chip(chip_type, chip_raw_data)\n",
    "    if chip_mapping:\n",
    "        return get_user_label_locations_from_chip_map(chip_mapping, user_chip_mapping)\n",
    "    return None\n",
    "\n",
    "user_chip_mapping = load_chip_feature_locations(chip_location_json, user_chip_mapping)\n",
    "if user_chip_mapping:\n",
    "    print('[INFO] User data updated successfully:')\n",
    "    pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "    pp.pprint(user_chip_mapping)\n",
    "else:\n",
    "    print('[ERROR] Something went wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2543873",
   "metadata": {},
   "source": [
    "## Calculate the rotation angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4213aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User data updated successfully:\n",
      "{   'chip_location_all_rotation_angles': [   -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0],\n",
      "    'chip_type': 'IMECII_2',\n",
      "    'features': [   {   'chip_location': [-2312, 960],\n",
      "                        'label': 'B-Left',\n",
      "                        'user_location': [1320, 5022]},\n",
      "                    {   'chip_location': [-2312, -40],\n",
      "                        'label': 'C-Left',\n",
      "                        'user_location': [1296, 3588]},\n",
      "                    {   'chip_location': [-2312, -1040],\n",
      "                        'label': 'D-Left',\n",
      "                        'user_location': [1254, 2178]},\n",
      "                    {   'chip_location': [-2312, -2040],\n",
      "                        'label': 'E-Left',\n",
      "                        'user_location': [1206, 768]}],\n",
      "    'rotation_angle': np.float64(1.620620406603308),\n",
      "    'user_location_all_rotation_angles': [   -90.95883566124951,\n",
      "                                             -91.32941027315728,\n",
      "                                             -91.53506251875962,\n",
      "                                             -91.706178294447,\n",
      "                                             -91.82796824430501,\n",
      "                                             -91.94974167210688],\n",
      "    'user_location_rotation_angle': np.float64(1.620620406603308)}\n"
     ]
    }
   ],
   "source": [
    "def angle_between_points(v1, v2):\n",
    "    \"\"\"Calculates the signed angle in degrees between the line connecting two vectors\n",
    "    and the positive x-axis.\n",
    "\n",
    "    Args:\n",
    "        v1: (x1, y1)\n",
    "        v2: (x2, y2)\n",
    "\n",
    "    Returns:\n",
    "        Angle in degrees, positive for counter-clockwise rotation from the\n",
    "        positive x-axis to the line segment from point1 to point2.\n",
    "    \"\"\"\n",
    "    x1, y1 = v1\n",
    "    x2, y2 = v2\n",
    "\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "\n",
    "    return math.degrees(math.atan2(dy, dx))  # Angle relative to positive x-axis\n",
    "\n",
    "\n",
    "def chip_rotation_angle(user_chip_mapping, key='user_location'):\n",
    "    locations = [a[key] for a in user_chip_mapping['features']]\n",
    "    chip_locations = [a['chip_location'] for a in user_chip_mapping['features']]\n",
    "\n",
    "    combination_idxs = list(itertools.combinations(range(len(locations)), 2))\n",
    "\n",
    "    location_combinations = [(locations[a], locations[b]) for (a, b) in combination_idxs]\n",
    "    chip_location_combinations = [(chip_locations[a], chip_locations[b]) for (a, b) in combination_idxs]\n",
    "\n",
    "    angles = [angle_between_points(a, b) for (a, b) in location_combinations]\n",
    "    chip_angles = [angle_between_points(a, b) for (a, b) in chip_location_combinations]\n",
    "\n",
    "    rotation_angles = [a - b for a, b in zip(chip_angles, angles)]\n",
    "\n",
    "    rotation_angle = np.quantile(rotation_angles, 0.5)\n",
    "\n",
    "    user_chip_mapping[f'{key}_all_rotation_angles'] = angles\n",
    "    user_chip_mapping['chip_location_all_rotation_angles'] = chip_angles\n",
    "\n",
    "    if 'refined' in key:\n",
    "        rotation_angle = user_chip_mapping['rotation_angle'] + rotation_angle\n",
    "\n",
    "    user_chip_mapping[f'{key}_rotation_angle'] = rotation_angle\n",
    "    user_chip_mapping['rotation_angle'] = rotation_angle\n",
    "\n",
    "    return user_chip_mapping, rotation_angle\n",
    "\n",
    "\n",
    "user_chip_mapping, _ = chip_rotation_angle(user_chip_mapping, key='user_location')\n",
    "if user_chip_mapping:\n",
    "    print('[INFO] User data updated successfully:')\n",
    "    pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "    pp.pprint(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f140d",
   "metadata": {},
   "source": [
    "## Calculate the scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6f4b07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_factor = np.float64(1.4146629305816565)\n",
      "User data updated successfully:\n",
      "{   'chip_location_all_rotation_angles': [   -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0],\n",
      "    'chip_type': 'IMECII_2',\n",
      "    'features': [   {   'chip_location': [-2312, 960],\n",
      "                        'label': 'B-Left',\n",
      "                        'user_location': [1320, 5022]},\n",
      "                    {   'chip_location': [-2312, -40],\n",
      "                        'label': 'C-Left',\n",
      "                        'user_location': [1296, 3588]},\n",
      "                    {   'chip_location': [-2312, -1040],\n",
      "                        'label': 'D-Left',\n",
      "                        'user_location': [1254, 2178]},\n",
      "                    {   'chip_location': [-2312, -2040],\n",
      "                        'label': 'E-Left',\n",
      "                        'user_location': [1206, 768]}],\n",
      "    'rotation_angle': np.float64(1.620620406603308),\n",
      "    'scale_factor': np.float64(1.4146629305816565),\n",
      "    'user_location_all_rotation_angles': [   -90.95883566124951,\n",
      "                                             -91.32941027315728,\n",
      "                                             -91.53506251875962,\n",
      "                                             -91.706178294447,\n",
      "                                             -91.82796824430501,\n",
      "                                             -91.94974167210688],\n",
      "    'user_location_all_scale_factors': [   1.4342008227580962,\n",
      "                                           1.4223828598517347,\n",
      "                                           1.4185090764602106,\n",
      "                                           1.4106253932210353,\n",
      "                                           1.4107179023461778,\n",
      "                                           1.4108167847031026],\n",
      "    'user_location_rotation_angle': np.float64(1.620620406603308),\n",
      "    'user_location_scale_factor': np.float64(1.4146629305816565)}\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(v1, v2):\n",
    "    \"\"\"Calculates the Euclidean distance between two points in 2D space.\n",
    "\n",
    "    Args:\n",
    "      v1: A tuple or list representing the first point (x1, y1).\n",
    "      v1: A tuple or list representing the second point (x2, y2).\n",
    "\n",
    "    Returns:\n",
    "      The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    x1, y1 = v1\n",
    "    x2, y2 = v2\n",
    "\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "def user_chip_scale_factor(user_chip_mapping, key='user_location'):\n",
    "    locations = [a[key] for a in user_chip_mapping['features']]\n",
    "    chip_locations = [a['chip_location'] for a in user_chip_mapping['features']]\n",
    "\n",
    "    combination_idxs = list(itertools.combinations(range(len(locations)), 2))\n",
    "\n",
    "    location_combinations = [(locations[a], locations[b]) for (a, b) in combination_idxs]\n",
    "    chip_location_combinations = [(chip_locations[a], chip_locations[b]) for (a, b) in combination_idxs]\n",
    "\n",
    "    distances = [calculate_distance(a, b) for (a, b) in location_combinations]\n",
    "    chip_distances = [calculate_distance(a, b) for (a, b) in chip_location_combinations]\n",
    "\n",
    "    scale_factors = [a / b for a, b in zip(distances, chip_distances)]\n",
    "\n",
    "    user_chip_mapping[f'{key}_all_scale_factors'] = scale_factors\n",
    "\n",
    "    scale_factor = np.quantile(scale_factors, 0.5)\n",
    "\n",
    "    user_chip_mapping[f'{key}_scale_factor'] = scale_factor\n",
    "    user_chip_mapping['scale_factor'] = scale_factor\n",
    "\n",
    "    # print(f'Distance between user features: {user_distance:.2f} pixels')\n",
    "    # print(f'Distance between map features: {chip_distance:.2f} microns')\n",
    "    # print(f'Scale factor: {scale_factor:.2f} pixels/micron')\n",
    "    return user_chip_mapping, scale_factor\n",
    "\n",
    "user_chip_mapping, scale_factor = user_chip_scale_factor(user_chip_mapping, key='user_location')\n",
    "if user_chip_mapping:\n",
    "    print(f'{scale_factor = }')\n",
    "    print('User data updated successfully:')\n",
    "    pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "    pp.pprint(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353bb31",
   "metadata": {},
   "source": [
    "## Rotate the image and user feature locations using calculated angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0bbb1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, rotation_angle):\n",
    "    \"\"\"\n",
    "    Rotates an image based on corresponding feature points.\n",
    "\n",
    "    Args:\n",
    "        image: The input image (OpenCV format).\n",
    "        rotation_angle: rotation angle\n",
    "\n",
    "    Returns:\n",
    "        rotated_image: The rotated image\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the center of rotation (midpoint of the image points)\n",
    "    h, w = image.shape\n",
    "    center = (w / 2, h / 2)\n",
    "\n",
    "    # Get the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "    # Apply the rotation and scaling\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def rotate_user_feature_locations(user_location, image_center, rotation_angle):\n",
    "    \"\"\"Rotates a point around a center by a given angle in degrees.\n",
    "\n",
    "    Args:\n",
    "        user_location: The point to rotate (x, y).\n",
    "        image_center: The center of rotation (x, y).\n",
    "        rotation_angle: rotation angle\n",
    "\n",
    "    Returns:\n",
    "        The rotated point (x, y).\n",
    "    \"\"\"\n",
    "    x, y = user_location\n",
    "    cx, cy = image_center\n",
    "    angle_rad = math.radians(rotation_angle)\n",
    "\n",
    "    rotated_x = cx + (x - cx) * math.cos(angle_rad) - (y - cy) * math.sin(angle_rad)\n",
    "    rotated_y = cy + (x - cx) * math.sin(angle_rad) + (y - cy) * math.cos(angle_rad)\n",
    "    return [int(rotated_x), int(rotated_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04f0e5",
   "metadata": {},
   "source": [
    "## Load template image and scale according to the scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e1db56f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_template(template_path):\n",
    "    \"\"\"\n",
    "    Loads a template image from the specified path.\n",
    "\n",
    "    Args:\n",
    "        template_path: Path to the template image.\n",
    "\n",
    "    Returns:\n",
    "        The loaded template image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if template is None:\n",
    "            raise ValueError(f\"Could not load image at {template_path}\")\n",
    "        return template\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading template: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d2e1ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_template(template, scale_factor):\n",
    "    \"\"\"Scales a template image by a given factor.\n",
    "\n",
    "    Args:\n",
    "        template: The template image (OpenCV format).\n",
    "        scale_factor: The scaling factor.\n",
    "\n",
    "    Returns:\n",
    "        The scaled template image.\n",
    "    \"\"\"\n",
    "    new_size = (int(template.shape[1] * scale_factor), int(template.shape[0] * scale_factor))\n",
    "    scaled_template = cv2.resize(template, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    return scaled_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e9753",
   "metadata": {},
   "source": [
    "## Find the location of the template in the image using cv2.matchTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c903af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_image_from_label(chip_type, label):\n",
    "    template_path = Path(f'../Label_templates/IMECII/{chip_type}/{label}.png')\n",
    "    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if template is None:\n",
    "        print(f\"Error: Could not load template image {template_path}.\")\n",
    "        return None\n",
    "    return template\n",
    "\n",
    "\n",
    "def refine_feature_locations(image, user_chip_mapping):\n",
    "    \"\"\"Refines the location of a feature using template matching,\n",
    "    accounting for image rotation.\n",
    "\n",
    "    Args:\n",
    "        image: The image to search in (already rotated).\n",
    "        initial_location: The initial (approximate) location of the feature (x, y) in the *original* image coordinates.\n",
    "        template: The template image of the feature.\n",
    "        rotation_angle: The angle by which the image was rotated (in degrees, clockwise).\n",
    "        image_center: The center of the rotation of the image.\n",
    "        scale_factor: Scaling factor for matching template size to image size\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The refined location (x, y) in the rotated image coordinates.\n",
    "            - The rotated initial location\n",
    "            - The original initial location\n",
    "        Returns (None, None, None) if template matching fails.\n",
    "    \"\"\"\n",
    "\n",
    "    chip_type = user_chip_mapping.get('chip_type')\n",
    "    rotation_angle = user_chip_mapping.get('rotation_angle', 0)\n",
    "    scale_factor = user_chip_mapping.get('scale_factor', 1.0)\n",
    "    image_center = (image.shape[1] / 2, image.shape[0] / 2)\n",
    "    user_features = user_chip_mapping.get('features', None)\n",
    "\n",
    "    if not user_features:\n",
    "        return None\n",
    "\n",
    "    for idx, f in enumerate(user_features):\n",
    "        label = f.get('label')\n",
    "        user_location = f.get('user_location')\n",
    "\n",
    "        # Rotate the user location to match the rotated image\n",
    "        rotated_user_location = rotate_user_feature_locations(user_location, image_center, rotation_angle)\n",
    "\n",
    "        # Load template image\n",
    "        template = get_template_image_from_label(chip_type, label)\n",
    "\n",
    "        # Scale template to match image size\n",
    "        template = scale_template(template, scale_factor)\n",
    "\n",
    "        # Define a search window around the rotated initial location\n",
    "        search_window_size = (template.shape[1] * 1.5, template.shape[0] * 1.5)\n",
    "        x_start = max(0, int(rotated_user_location[0] - search_window_size[0] / 2))\n",
    "        y_start = max(0, int(rotated_user_location[1] - search_window_size[1] / 2))\n",
    "        x_end = min(image.shape[1], int(rotated_user_location[0] + search_window_size[0] / 2))\n",
    "        y_end = min(image.shape[0], int(rotated_user_location[1] + search_window_size[1] / 2))\n",
    "\n",
    "        search_window = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Pre-process the search window to match the template type\n",
    "          # Sharpen the search window\n",
    "        blurred = cv2.GaussianBlur(search_window, (25, 25), 0)\n",
    "        sharpened_search_window = cv2.addWeighted(search_window, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "          # Binarise the search window to match the template\n",
    "        _, binarized_search_window = cv2.threshold(sharpened_search_window, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "        visualize_search_window_preprocessing(search_window, sharpened_search_window, binarized_search_window)\n",
    "\n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(binarized_search_window, template, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        # Calculate a quality metric (e.g., peak-to-mean ratio)\n",
    "        mean_val = np.mean(result)\n",
    "        quality_metric = max_val / mean_val if mean_val > 0 else 0  # Avoid division by zero\n",
    "        visualize_template_matching_result(search_window, result, max_loc, max_val, mean_val, quality_metric)\n",
    "\n",
    "        if quality_metric > 1.5 and max_val > 0.5:  # Example threshold. Adjust as needed.\n",
    "            refined_x = x_start + max_loc[0]\n",
    "            refined_y = y_start + max_loc[1]\n",
    "            user_chip_mapping['features'][idx]['refined_location'] = [refined_x, refined_y]\n",
    "            user_chip_mapping['features'][idx]['match_quality'] = quality_metric  # Store the quality\n",
    "            is_good_match = True\n",
    "            user_chip_mapping['features'][idx]['label_locating_success'] = is_good_match\n",
    "        else:\n",
    "            refined_x = None\n",
    "            refined_y = None\n",
    "            user_chip_mapping['features'][idx]['refined_location'] = None\n",
    "            user_chip_mapping['features'][idx]['match_quality'] = quality_metric\n",
    "            is_good_match = False\n",
    "            user_chip_mapping['features'][idx]['label_locating_success'] = is_good_match\n",
    "    return user_chip_mapping, [refined_x, refined_y], template.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fe780",
   "metadata": {},
   "source": [
    "## Visualise results with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7f621ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_search_window_preprocessing(original_search_window, sharpened_search_window, binarized_search_window, plot=PLOT):\n",
    "    \"\"\"\n",
    "    Visualizes the original, sharpened, and binarized search windows using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        original_search_window: The original search window image.\n",
    "        sharpened_search_window: The sharpened search window image.\n",
    "        binarized_search_window: The binarized search window image.\n",
    "    \"\"\"\n",
    "    if not plot:\n",
    "        return\n",
    "\n",
    "    # Create a Matplotlib figure with three subplots in one row\n",
    "    _, axes = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns, adjust figure size as needed\n",
    "\n",
    "    # Display the original search window in the first subplot\n",
    "    axes[0].imshow(cv2.cvtColor(original_search_window, cv2.COLOR_BGR2RGB))  # Convert to RGB for Matplotlib\n",
    "    axes[0].set_title('Original Search Window')\n",
    "    axes[0].axis('off')  # Turn off axis labels\n",
    "\n",
    "    # Display the sharpened search window in the second subplot\n",
    "    axes[1].imshow(cv2.cvtColor(sharpened_search_window, cv2.COLOR_BGR2RGB))  # Convert to RGB\n",
    "    axes[1].set_title('Sharpened Search Window')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Display the binarized search window in the third subplot\n",
    "    axes[2].imshow(cv2.cvtColor(binarized_search_window, cv2.COLOR_BGR2RGB))  # Otherwise, convert to RGB\n",
    "    axes[2].set_title('Binarized Search Window')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4e56d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_template_matching_result(search_window, result, max_loc, max_val, mean_val, quality_metric, plot=PLOT):\n",
    "    \"\"\"\n",
    "    Visualizes the search window and the template matching result with the\n",
    "    location of the maximum match.\n",
    "\n",
    "    Args:\n",
    "        search_window: The image search window.\n",
    "        result: The template matching result image.\n",
    "        max_loc: The (x, y) location of the maximum value in the result.\n",
    "    \"\"\"\n",
    "    if not plot:\n",
    "        return\n",
    "\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Display the search window\n",
    "    ax1.imshow(cv2.cvtColor(search_window, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Search Window')\n",
    "    circle1 = patches.Circle(max_loc, 5, color='red', fill=False)\n",
    "    ax1.add_patch(circle1)\n",
    "\n",
    "    # Display the template matching result\n",
    "    ax2.imshow(result, cmap='gray')\n",
    "    ax2.set_title(f'Template Matching Result\\n{max_val =:.2f}\\n{mean_val =:.2f}\\n{quality_metric =:.2f}')\n",
    "    circle2 = patches.Circle(max_loc, 5, color='red', fill=False)\n",
    "    ax2.add_patch(circle2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7c8d0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features_with_matplotlib(rotated_image, chip_mapping, feature_shape, key='features', plot=PLOT):\n",
    "    \"\"\"\n",
    "    Visualizes user and refined feature locations on a rotated image using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        rotated_image: The rotated image (OpenCV format).\n",
    "        chip_mapping: A dictionary containing feature information, including\n",
    "            user and refined locations.  Assumed to have the same structure\n",
    "            as the `user_features` variable in previous examples.\n",
    "        feature_shape:  The shape (height, width) of the feature, needed to draw the rectangle.\n",
    "    \"\"\"\n",
    "    if not plot:\n",
    "        return\n",
    "\n",
    "    # Convert the OpenCV image to RGB format for Matplotlib\n",
    "    rotated_image_rgb = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a Matplotlib figure and axes\n",
    "    _, ax = plt.subplots(1, figsize=(12, 12))\n",
    "    ax.imshow(rotated_image_rgb)  # Display the image\n",
    "\n",
    "    if 'features' in key:\n",
    "        features = chip_mapping.get(key, None)  # Get the features list.\n",
    "    if 'gratings' in key:\n",
    "        features = chip_mapping\n",
    "\n",
    "    if features:\n",
    "        for f in features:\n",
    "            label = f.get('label')\n",
    "            if 'features' in key:\n",
    "                location = f.get('refined_location')\n",
    "            if 'gratings' in key:\n",
    "                location = f.get('grating_origin')\n",
    "\n",
    "            if location:\n",
    "                x, y = location\n",
    "                # height, width = (10, 10)\n",
    "                if feature_shape:\n",
    "                    height, width = feature_shape  # Corrected order for Matplotlib\n",
    "                else:\n",
    "                    width = f.get('x-size')\n",
    "                    height = f.get('y-size')\n",
    "\n",
    "                rect = patches.Rectangle((x, y), width, height, linewidth=1,\n",
    "                                         edgecolor='white', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.annotate(label, location, color='white',\n",
    "                            fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Rotated Image with features highlighted')\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35688ab4",
   "metadata": {},
   "source": [
    "## Calculate image offset from chip map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "086081cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chip_offset(user_chip_mapping):\n",
    "    user_features = user_chip_mapping.get('features', None)\n",
    "    scale_factor = user_chip_mapping.get('scale_factor', 1.0)\n",
    "\n",
    "    if not user_features:\n",
    "        return None\n",
    "\n",
    "    x_offsets = []\n",
    "    y_offsets = []\n",
    "    for idx, f in enumerate(user_features):\n",
    "        offset = [a - (b * scale_factor) for a, b in zip(f['refined_location'], f['chip_location'])]\n",
    "        x_offsets.append(offset[0])\n",
    "        y_offsets.append(offset[1])\n",
    "        user_chip_mapping['features'][idx]['feature_offset'] = offset\n",
    "\n",
    "    user_chip_mapping['offset'] = [np.quantile(x_offsets, 0.5), np.quantile(y_offsets, 0.5)]\n",
    "    return user_chip_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca59c2e",
   "metadata": {},
   "source": [
    "## Load and offset grating locations from chip map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0babda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None]\n",
      "[ERROR] Something went wrong\n"
     ]
    }
   ],
   "source": [
    "def offset_and_scale_grating_data(grating_mapping, user_chip_mapping):\n",
    "    offset = user_chip_mapping.get('offset', [None, None])\n",
    "    scale_factor = user_chip_mapping['scale_factor']\n",
    "    if offset[0]:\n",
    "        for idx, grating in enumerate(grating_mapping):\n",
    "            offset_grating_origin = [int((a * scale_factor) + b) for a, b in zip(grating['grating_origin'], offset)]\n",
    "            grating_mapping[idx]['grating_origin'] = offset_grating_origin\n",
    "            grating_mapping[idx]['x-size'] = int(grating['x-size'] * scale_factor)\n",
    "            grating_mapping[idx]['y-size'] = int(grating['y-size'] * scale_factor)\n",
    "        return grating_mapping\n",
    "    return None\n",
    "\n",
    "def load_and_offset_grating_data(file_path, user_chip_mapping):\n",
    "    chip_raw_data = load_json(file_path)\n",
    "    chip_type = user_chip_mapping.get('chip_type')\n",
    "    chip_mapping = get_type_of_chip(chip_type, chip_raw_data)\n",
    "    if chip_mapping:\n",
    "        raw_grating_mapping = chip_mapping.get('gratings', None)\n",
    "    if raw_grating_mapping:\n",
    "        return offset_and_scale_grating_data(raw_grating_mapping, user_chip_mapping)\n",
    "    return None\n",
    "\n",
    "chip_mapping = load_and_offset_grating_data(chip_location_json, user_chip_mapping)\n",
    "if chip_mapping:\n",
    "    print('[INFO] User data updated successfully:')\n",
    "    pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "    pp.pprint(chip_mapping)\n",
    "else:\n",
    "    print('[ERROR] Something went wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d18f3",
   "metadata": {},
   "source": [
    "## Create ROI JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fb28e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ROI_JSON(chip_type, grating_data, target_shape, rotation_angle, ROI_path):\n",
    "    ROIs = {}\n",
    "    if 'IMECII_2' in chip_type:\n",
    "        suffix = ['N', 'S']\n",
    "        for g in grating_data:\n",
    "            x, y = g['grating_origin']\n",
    "            if (\n",
    "                x < 0\n",
    "                or y < 0\n",
    "                or x + g['x-size'] > target_shape[1]\n",
    "                or y + g['y-size'] > target_shape[0]\n",
    "            ):\n",
    "                continue\n",
    "            ROIs[f'ROI_{g[\"label\"]}_{suffix[0]}'] = {\n",
    "                'label': f'{g[\"label\"]}_{suffix[0]}',\n",
    "                'flip': True,\n",
    "                'coords': [y + g['y-size'] // 2, x],\n",
    "                'size': [g['y-size'] // 2, g['x-size']],\n",
    "            }\n",
    "            ROIs[f'ROI_{g[\"label\"]}_{suffix[1]}'] = {\n",
    "                'label': f'{g[\"label\"]}_{suffix[1]}',\n",
    "                'flip': False,\n",
    "                'coords': [y, x],\n",
    "                'size': [g['y-size'] // 2, g['x-size']],\n",
    "            }\n",
    "    else:\n",
    "        suffix = ['A', 'B']\n",
    "        for g in grating_data:\n",
    "            x, y = g['grating_origin']\n",
    "            if (\n",
    "                x < 0\n",
    "                or y < 0\n",
    "                or x + g['x-size'] > target_shape[1]\n",
    "                or y + g['y-size'] > target_shape[0]\n",
    "            ):\n",
    "                continue\n",
    "            ROIs[f'ROI_{g[\"label\"]}_{suffix[0]}'] = {\n",
    "                'label': f'{g[\"label\"]}_{suffix[0]}',\n",
    "                'flip': True,\n",
    "                'coords': [y, x],\n",
    "                'size': [g['y-size'], g['x-size'] // 2],\n",
    "            }\n",
    "            ROIs[f'ROI_{g[\"label\"]}_{suffix[1]}'] = {\n",
    "                'label': f'{g[\"label\"]}_{suffix[1]}',\n",
    "                'flip': False,\n",
    "                'coords': [y, x + g['x-szie'] // 2],\n",
    "                'size': [g['y-size'], g['x-size'] // 2],\n",
    "            }\n",
    "    ROIs['image_angle'] = rotation_angle\n",
    "    with open(ROI_path, 'w') as file:\n",
    "        json.dump(ROIs, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8e1f2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(4509.975584075422), np.float64(3516.5904979780735)]\n",
      "User chip mapping:\n",
      "{   'chip_location_all_rotation_angles': [   -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0,\n",
      "                                             -90.0],\n",
      "    'chip_type': 'IMECII_2',\n",
      "    'features': [   {   'chip_location': [-2312, 960],\n",
      "                        'feature_offset': [   np.float64(4508.475584075422),\n",
      "                                              np.float64(3517.754082736849)],\n",
      "                        'label': 'B-Left',\n",
      "                        'label_locating_success': True,\n",
      "                        'match_quality': np.float32(1.5597569),\n",
      "                        'refined_location': [1247, 4872],\n",
      "                        'user_location': [1320, 5022]},\n",
      "                    {   'chip_location': [-2312, -40],\n",
      "                        'feature_offset': [   np.float64(4510.475584075422),\n",
      "                                              np.float64(3515.426913219298)],\n",
      "                        'label': 'C-Left',\n",
      "                        'label_locating_success': True,\n",
      "                        'match_quality': np.float32(2.0587158),\n",
      "                        'refined_location': [1249, 3459],\n",
      "                        'user_location': [1296, 3588]},\n",
      "                    {   'chip_location': [-2312, -1040],\n",
      "                        'feature_offset': [   np.float64(4510.475584075422),\n",
      "                                              np.float64(3514.0997437017472)],\n",
      "                        'label': 'D-Left',\n",
      "                        'label_locating_success': True,\n",
      "                        'match_quality': np.float32(1.946932),\n",
      "                        'refined_location': [1249, 2047],\n",
      "                        'user_location': [1254, 2178]},\n",
      "                    {   'chip_location': [-2312, -2040],\n",
      "                        'feature_offset': [   np.float64(4509.475584075422),\n",
      "                                              np.float64(3521.7725741841964)],\n",
      "                        'label': 'E-Left',\n",
      "                        'label_locating_success': True,\n",
      "                        'match_quality': np.float32(1.9366446),\n",
      "                        'refined_location': [1248, 644],\n",
      "                        'user_location': [1206, 768]}],\n",
      "    'offset': [np.float64(4509.975584075422), np.float64(3516.5904979780735)],\n",
      "    'refined_location_all_rotation_angles': [   -89.75670728173516,\n",
      "                                                -89.79718392848538,\n",
      "                                                -89.82383093982453,\n",
      "                                                -89.83768944406332,\n",
      "                                                -89.85752411015552,\n",
      "                                                -89.87748604663506],\n",
      "    'refined_location_all_scale_factors': [   1.4130127387960805,\n",
      "                                              1.4125088495298004,\n",
      "                                              1.4093399952538856,\n",
      "                                              1.4120056657110127,\n",
      "                                              1.4075043516806618,\n",
      "                                              1.4030032074090208],\n",
      "    'refined_location_rotation_angle': np.float64(1.4513805985472317),\n",
      "    'refined_location_scale_factor': np.float64(1.4106728304824492),\n",
      "    'rotation_angle': np.float64(1.4513805985472317),\n",
      "    'scale_factor': np.float64(1.4106728304824492),\n",
      "    'user_location_all_rotation_angles': [   -90.95883566124951,\n",
      "                                             -91.32941027315728,\n",
      "                                             -91.53506251875962,\n",
      "                                             -91.706178294447,\n",
      "                                             -91.82796824430501,\n",
      "                                             -91.94974167210688],\n",
      "    'user_location_all_scale_factors': [   1.4342008227580962,\n",
      "                                           1.4223828598517347,\n",
      "                                           1.4185090764602106,\n",
      "                                           1.4106253932210353,\n",
      "                                           1.4107179023461778,\n",
      "                                           1.4108167847031026],\n",
      "    'user_location_rotation_angle': np.float64(1.620620406603308),\n",
      "    'user_location_scale_factor': np.float64(1.4146629305816565)}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to perform image alignment and feature localization.\"\"\"\n",
    "# 1. Load data\n",
    "feature_location_json = Path('../config/FeatureLocation.json')\n",
    "chip_location_json = Path('../Label_templates/Chip_map_list.json')\n",
    "ROI_json = Path('../Generated_files/ROI_ChirpArray_TEST.json')\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "image = cv2.normalize(\n",
    "        image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U # type: ignore\n",
    "    )  # Normalize to 8-bit range (0-255)\n",
    "if len(image.shape) > 2:  # Check if the image has more than one channel (i.e., it's not already greyscale)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "if image is None:\n",
    "    print(f\"[ERROR] Could not load image from {image_path}\")\n",
    "    exit(1)\n",
    "\n",
    "user_chip_mapping = load_user_feature_locations(feature_location_json)\n",
    "user_chip_mapping = load_chip_feature_locations(chip_location_json, user_chip_mapping)\n",
    "\n",
    "# 2. Calculate angle and scale according to user's input\n",
    "user_chip_mapping, initial_rotation_angle = chip_rotation_angle(user_chip_mapping, key='user_location')\n",
    "user_chip_mapping, _ = user_chip_scale_factor(user_chip_mapping)\n",
    "\n",
    "# 3. Rotate image using user angle\n",
    "rotated_image = rotate_image(image, -initial_rotation_angle)\n",
    "if rotated_image is None:\n",
    "    print(\"[ERROR] Image rotation and scaling failed.\")\n",
    "    exit(1)\n",
    "\n",
    "# 4. Refine feature locations using template matching\n",
    "user_chip_mapping, refined_locations, _ = refine_feature_locations(rotated_image, user_chip_mapping)\n",
    "\n",
    "if not refined_locations:\n",
    "    print(f'[ERROR] Label locating failed')\n",
    "    exit(1)\n",
    "\n",
    "# 5. Calculate rotation-angle / scale-factor of image from locatedd the image features (not from user input locations)\n",
    "user_chip_mapping, refined_rotation_angle = chip_rotation_angle(user_chip_mapping, key='refined_location')\n",
    "# user_chip_mapping['rotation_angle'] = initial_rotation_angle + refined_rotation_angle\n",
    "user_chip_mapping, refined_scale_factor = user_chip_scale_factor(user_chip_mapping, key='refined_location')\n",
    "\n",
    "# 6. Rotate image by refined rotation angle\n",
    "rotated_image = rotate_image(image, -user_chip_mapping['rotation_angle'])\n",
    "if rotated_image is None:\n",
    "    print(\"[ERROR] Image rotation and scaling failed.\")\n",
    "    exit(1)\n",
    "\n",
    "# 6. Refine feature locations again with new rotation-angle / scale-factor using template matching\n",
    "user_chip_mapping, refined_locations, template_shape = refine_feature_locations(rotated_image, user_chip_mapping)\n",
    "\n",
    "# 7. Calculate offset between image and chip-map\n",
    "user_chip_mapping = calculate_chip_offset(user_chip_mapping)\n",
    "\n",
    "# 8. Load and offset grating locations\n",
    "grating_data = load_and_offset_grating_data(chip_location_json, user_chip_mapping)\n",
    "\n",
    "# 9.. Visualise feature location results\n",
    "visualize_features_with_matplotlib(rotated_image, user_chip_mapping, template_shape, key='features')\n",
    "\n",
    "# 10. Visualise grating location results\n",
    "visualize_features_with_matplotlib(rotated_image, grating_data, None, key='gratings')\n",
    "\n",
    "# 11. Display results\n",
    "pp = pprint.PrettyPrinter(indent=4)  # Create a PrettyPrinter object\n",
    "print('User chip mapping:')\n",
    "pp.pprint(user_chip_mapping)\n",
    "\n",
    "# 12. Create ROI JSON file\n",
    "chip_type = user_chip_mapping['chip_type']\n",
    "rotation_angle = user_chip_mapping['rotation_angle']\n",
    "create_ROI_JSON(chip_type, grating_data, rotated_image.shape, rotation_angle, ROI_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4252d28",
   "metadata": {},
   "source": [
    "## Validate auto-label locating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "18d642bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_location_all_rotation_angles : STD : 0.3316124767119831\n",
      "refined_location_all_rotation_angles : STD : 0.039607640428723154\n",
      "user_location_all_scale_factors : STD : 0.008571800561907645\n",
      "refined_location_all_scale_factors : STD : 0.0035086555864888014\n",
      "\n",
      "user_location_all_rotation_angles : MEDIAN : -91.62062040660331\n",
      "user_location_all_rotation_angles : MEAN : -91.55119944400421\n",
      "refined_location_all_rotation_angles : MEDIAN : -89.83076019194392\n",
      "refined_location_all_rotation_angles : MEAN : -89.82507029181649\n",
      "user_location_all_scale_factors : MEDIAN : 1.4146629305816565\n",
      "user_location_all_scale_factors : MEAN : 1.4178754732233931\n",
      "refined_location_all_scale_factors : MEDIAN : 1.4106728304824492\n",
      "refined_location_all_scale_factors : MEAN : 1.4095624680634102\n"
     ]
    }
   ],
   "source": [
    "keys = [\n",
    "        'user_location_all_rotation_angles',\n",
    "        'refined_location_all_rotation_angles',\n",
    "        'user_location_all_scale_factors',\n",
    "        'refined_location_all_scale_factors',\n",
    "        ]\n",
    "\n",
    "for k in keys:\n",
    "    temp = user_chip_mapping.get(k)\n",
    "    print(f'{k} : STD : {np.std(temp)}')\n",
    "\n",
    "print('')\n",
    "\n",
    "for k in keys:\n",
    "    temp = user_chip_mapping.get(k)\n",
    "    print(f'{k} : MEDIAN : {np.quantile(temp, 0.5)}')\n",
    "    print(f'{k} : MEAN : {np.mean(temp)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
