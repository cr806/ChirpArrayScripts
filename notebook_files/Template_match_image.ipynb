{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d4ac02",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a050c3",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38077b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_location_json = Path('../config/FeatureLocation.json')\n",
    "chip_location_json = Path('../Label_templates/Chip_map_list.json')\n",
    "\n",
    "image_path = Path('/Volumes/krauss/Lisa/GMR/Array/250325/loc1_1/Pos0/img_000000000_Default_000.tif')\n",
    "\n",
    "b_left_template_path = Path('../Label_templates/IMECII/IMECII_2/B-Left.png')\n",
    "e_left_template_path = Path('../Label_templates/IMECII/IMECII_2/E-Left.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2139dbc",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. ☑ Load user feature location JSON file\n",
    "\n",
    "2. ☑ Calculate the scale factor and image angle using the user feature location\n",
    "\n",
    "3. ☑ Load the chip map JSON file and extract the labels location\n",
    "\n",
    "4. ☑ Calculate the scale factor and image angle using the chip map\n",
    "\n",
    "5. ☑ Rotate the image and user feature locations using calculated angle\n",
    "\n",
    "6. ☑ Load template image and scale according to the scale factor\n",
    "\n",
    "7. ☑ Find the location of the template in the image using cv2.matchTemplate\n",
    "\n",
    "8. ☐ Display the results of the template matching on the image\n",
    "\n",
    "9. ☐ Calculate some FOM values based on the template matching results\n",
    "\n",
    "10. ☐ If matching FOM is below some threshold, attempt to match with a different technigue\n",
    "\n",
    "11. ☐ Comparem matching results, if one is better, use that one\n",
    "\n",
    "12. ☐ Calculate chip map transformation to match image\n",
    "\n",
    "13. ☐ Save list of ROIs (i.e. grating locations) to a JSON file using transformation\n",
    "\n",
    "☐ Unchecked\n",
    "☑ Checked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2152e",
   "metadata": {},
   "source": [
    "## Load user feature locations from JSON file and populate 'user_chip_mapping' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from '{file_path}'. Check the file format.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70148129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data loaded successfully:\n",
      "{'chip_type': 'IMECII_2', 'features': [{'label': 'D-Right', 'user_location': [1840, 849]}, {'label': 'E-Right', 'user_location': [1848, 122]}]}\n"
     ]
    }
   ],
   "source": [
    "def load_user_feature_locations(file_path):\n",
    "    user_raw_data = load_json(file_path)\n",
    "    user_chip_mapping = {}\n",
    "    if user_raw_data:\n",
    "        user_chip_mapping['chip_type'] = user_raw_data.get('chip_type', None)\n",
    "        features = []\n",
    "        for feature in user_raw_data.get('features', []):\n",
    "            label_name = feature.get('label')\n",
    "            feature_location = feature.get('feature_location')\n",
    "            if label_name:\n",
    "                features.append({\n",
    "                    'label': label_name,\n",
    "                    'user_location': feature_location\n",
    "                })\n",
    "        user_chip_mapping['features'] = features\n",
    "    else:\n",
    "        print(\"No valid data to load.\")\n",
    "    return user_chip_mapping\n",
    "\n",
    "user_chip_mapping = load_user_feature_locations(feature_location_json)\n",
    "\n",
    "if user_chip_mapping:\n",
    "    print('User data loaded successfully:')\n",
    "    print(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdeb03",
   "metadata": {},
   "source": [
    "## Load chip map locations from JSON and update 'user_chip_map' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "221bd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data updated successfully:\n",
      "{'chip_type': 'IMECII_2', 'features': [{'label': 'D-Right', 'user_location': [1840, 849], 'chip_location': [2261, -1040]}, {'label': 'E-Right', 'user_location': [1848, 122], 'chip_location': [2261, -2040]}]}\n"
     ]
    }
   ],
   "source": [
    "def get_type_of_chip(chip_type, all_chip_mappings):\n",
    "    for chip_mapping in all_chip_mappings:\n",
    "        chip_name_label = chip_mapping.get('chip_type', None)\n",
    "        if chip_name_label == chip_type:\n",
    "            return chip_mapping\n",
    "    return None\n",
    "\n",
    "def get_location_from_label(label, chip_mapping):\n",
    "    for chip_label in chip_mapping.get('labels'):\n",
    "        if chip_label.get('label') == label:\n",
    "            return chip_label.get('label_origin', None)\n",
    "    return None\n",
    "\n",
    "def get_user_label_locations_from_chip_map(chip_mapping, user_chip_mapping):\n",
    "    user_features = user_chip_mapping.get('features', None)\n",
    "    if user_features:\n",
    "        for idx, f in enumerate(user_features):\n",
    "            label = f.get('label')\n",
    "            feature_location = get_location_from_label(label, chip_mapping)\n",
    "            user_chip_mapping['features'][idx]['chip_location'] = feature_location\n",
    "    return user_chip_mapping\n",
    "\n",
    "def load_chip_feature_locations(file_path, user_chip_mapping):\n",
    "    chip_raw_data = load_json(file_path)\n",
    "    chip_type = user_chip_mapping.get('chip_type')\n",
    "    chip_mapping = get_type_of_chip(chip_type, chip_raw_data)\n",
    "    return get_user_label_locations_from_chip_map(chip_mapping, user_chip_mapping)\n",
    "\n",
    "user_chip_mapping = load_chip_feature_locations(chip_location_json, user_chip_mapping)\n",
    "if user_chip_mapping:\n",
    "    print('User data updated successfully:')\n",
    "    print(user_chip_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2543873",
   "metadata": {},
   "source": [
    "## Calculate the scale factor and image angle using the user feature location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4213aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data updated successfully:\n",
      "{'chip_type': 'IMECII_2', 'features': [{'label': 'D-Right', 'user_location': [1840, 849], 'chip_location': [2261, -1040], 'refined_location': [1822, 825]}, {'label': 'E-Right', 'user_location': [1848, 122], 'chip_location': [2261, -2040], 'refined_location': [1817, 99]}], 'rotation_angle': -0.6304645613991369, 'scale_factor': 0.7270440151737719, 'user_location_angle': -89.36953543860086, 'chip_location_angle': -90.0}\n"
     ]
    }
   ],
   "source": [
    "def angle_between_points(v1, v2):\n",
    "    \"\"\"Calculates the signed angle in degrees between the line connecting two vectors\n",
    "    and the positive x-axis.\n",
    "\n",
    "    Args:\n",
    "        v1: (x1, y1)\n",
    "        v2: (x2, y2)\n",
    "\n",
    "    Returns:\n",
    "        Angle in degrees, positive for counter-clockwise rotation from the\n",
    "        positive x-axis to the line segment from point1 to point2.\n",
    "    \"\"\"\n",
    "    x1, y1 = v1\n",
    "    x2, y2 = v2\n",
    "\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "\n",
    "    return math.degrees(math.atan2(dy, dx))  # Angle relative to positive x-axis\n",
    "\n",
    "\n",
    "def user_chip_rotation_angle(user_chip_mapping):\n",
    "  image_f1 = user_chip_mapping['features'][0]['user_location']\n",
    "  image_f2 = user_chip_mapping['features'][1]['user_location']\n",
    "  image_angle = angle_between_points(image_f1, image_f2)\n",
    "\n",
    "  chip_f1 = user_chip_mapping['features'][0]['chip_location']\n",
    "  chip_f2 = user_chip_mapping['features'][1]['chip_location']\n",
    "  map_angle = angle_between_points(chip_f1, chip_f2)\n",
    "\n",
    "  rotation_angle = map_angle - image_angle\n",
    "\n",
    "  user_chip_mapping['user_location_angle'] = image_angle\n",
    "  user_chip_mapping['chip_location_angle'] = map_angle\n",
    "  user_chip_mapping['rotation_angle'] = rotation_angle\n",
    "\n",
    "  # print(f'Angle between user features: {image_angle:.2f} degrees')\n",
    "  # print(f'Angle between map features: {map_angle:.2f} degrees')\n",
    "  # print(f'Rotation angle: {rotation_angle:.2f} degrees')\n",
    "  return user_chip_mapping, rotation_angle\n",
    "\n",
    "\n",
    "user_chip_mapping, _ = user_chip_rotation_angle(user_chip_mapping)\n",
    "if user_chip_mapping:\n",
    "    print('User data updated successfully:')\n",
    "    print(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f4b07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data updated successfully:\n",
      "{'chip_type': 'IMECII_2', 'features': [{'label': 'D-Right', 'user_location': [1840, 849], 'chip_location': [2261, -1040]}, {'label': 'E-Right', 'user_location': [1848, 122], 'chip_location': [2261, -2040]}], 'rotation_angle': -0.6304645613991369, 'scale_factor': 0.7270440151737719}\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(v1, v2):\n",
    "    \"\"\"Calculates the Euclidean distance between two points in 2D space.\n",
    "\n",
    "    Args:\n",
    "      v1: A tuple or list representing the first point (x1, y1).\n",
    "      v1: A tuple or list representing the second point (x2, y2).\n",
    "\n",
    "    Returns:\n",
    "      The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    x1, y1 = v1\n",
    "    x2, y2 = v2\n",
    "\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "def user_chip_scale_factor(user_chip_mapping):\n",
    "    f1 = user_chip_mapping['features'][0]['user_location']\n",
    "    f2 = user_chip_mapping['features'][1]['user_location']\n",
    "    user_distance = calculate_distance(f1, f2)\n",
    "\n",
    "    f1 = user_chip_mapping['features'][0]['chip_location']\n",
    "    f2 = user_chip_mapping['features'][1]['chip_location']\n",
    "    chip_distance = calculate_distance(f1, f2)\n",
    "\n",
    "    scale_factor = user_distance / chip_distance\n",
    "\n",
    "    user_chip_mapping['scale_factor'] = scale_factor\n",
    "\n",
    "    # print(f'Distance between user features: {user_distance:.2f} pixels')\n",
    "    # print(f'Distance between map features: {chip_distance:.2f} microns')\n",
    "    # print(f'Scale factor: {scale_factor:.2f} pixels/micron')\n",
    "    return user_chip_mapping, scale_factor\n",
    "\n",
    "user_chip_mapping, _ = user_chip_scale_factor(user_chip_mapping)\n",
    "if user_chip_mapping:\n",
    "    print('User data updated successfully:')\n",
    "    print(user_chip_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353bb31",
   "metadata": {},
   "source": [
    "## Rotate the image and user feature locations using calculated angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bbb1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, rotation_angle):\n",
    "    \"\"\"\n",
    "    Rotates an image based on corresponding feature points.\n",
    "\n",
    "    Args:\n",
    "        image: The input image (OpenCV format).\n",
    "        rotation_angle: rotation angle\n",
    "\n",
    "    Returns:\n",
    "        rotated_image: The rotated image\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the center of rotation (midpoint of the image points)\n",
    "    h, w = image.shape\n",
    "    center = (w / 2, h / 2)\n",
    "\n",
    "    # Get the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "    # Apply the rotation and scaling\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def rotate_user_feature_locations(user_location, image_center, rotation_angle):\n",
    "    \"\"\"Rotates a point around a center by a given angle in degrees.\n",
    "\n",
    "    Args:\n",
    "        user_location: The point to rotate (x, y).\n",
    "        image_center: The center of rotation (x, y).\n",
    "        rotation_angle: rotation angle\n",
    "\n",
    "    Returns:\n",
    "        The rotated point (x, y).\n",
    "    \"\"\"\n",
    "    x, y = user_location\n",
    "    cx, cy = image_center\n",
    "    angle_rad = math.radians(rotation_angle)\n",
    "\n",
    "    rotated_x = cx + (x - cx) * math.cos(angle_rad) - (y - cy) * math.sin(angle_rad)\n",
    "    rotated_y = cy + (x - cx) * math.sin(angle_rad) + (y - cy) * math.cos(angle_rad)\n",
    "    return [int(rotated_x), int(rotated_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04f0e5",
   "metadata": {},
   "source": [
    "## Load template image and scale according to the scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1db56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of B-Left template: (80, 57)\n",
      "Shape of E-Left template: (80, 57)\n"
     ]
    }
   ],
   "source": [
    "def load_template(template_path):\n",
    "    \"\"\"\n",
    "    Loads a template image from the specified path.\n",
    "\n",
    "    Args:\n",
    "        template_path: Path to the template image.\n",
    "\n",
    "    Returns:\n",
    "        The loaded template image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if template is None:\n",
    "            raise ValueError(f\"Could not load image at {template_path}\")\n",
    "        return template\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading template: {e}\")\n",
    "        return None\n",
    "\n",
    "b_left_template = load_template(b_left_template_path)\n",
    "e_left_template = load_template(e_left_template_path)\n",
    "\n",
    "print(f'Shape of B-Left template: {b_left_template.shape}')\n",
    "print(f'Shape of E-Left template: {e_left_template.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2e1ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shape of B-Left template: (40, 28)\n",
      "Scaled shape of E-Left template: (40, 28)\n"
     ]
    }
   ],
   "source": [
    "def scale_template(template, scale_factor):\n",
    "    \"\"\"Scales a template image by a given factor.\n",
    "\n",
    "    Args:\n",
    "        template: The template image (OpenCV format).\n",
    "        scale_factor: The scaling factor.\n",
    "\n",
    "    Returns:\n",
    "        The scaled template image.\n",
    "    \"\"\"\n",
    "    new_size = (int(template.shape[1] * scale_factor), int(template.shape[0] * scale_factor))\n",
    "    scaled_template = cv2.resize(template, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    return scaled_template\n",
    "\n",
    "scaled_b_left_template = scale_template(b_left_template, 0.5)\n",
    "scaled_e_left_template = scale_template(e_left_template, 0.5)\n",
    "\n",
    "print(f'Scaled shape of B-Left template: {scaled_b_left_template.shape}')\n",
    "print(f'Scaled shape of E-Left template: {scaled_e_left_template.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e9753",
   "metadata": {},
   "source": [
    "## Find the location of the template in the image using cv2.matchTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c903af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_image_from_label(chip_type, label):\n",
    "    template_path = Path(f'../Label_templates/IMECII/{chip_type}/{label}.png')\n",
    "    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if template is None:\n",
    "        print(f\"Error: Could not load template image {template_path}.\")\n",
    "        return None\n",
    "    return template\n",
    "\n",
    "\n",
    "def refine_feature_locations(image, user_chip_mapping):\n",
    "    \"\"\"Refines the location of a feature using template matching,\n",
    "    accounting for image rotation.\n",
    "\n",
    "    Args:\n",
    "        image: The image to search in (already rotated).\n",
    "        initial_location: The initial (approximate) location of the feature (x, y) in the *original* image coordinates.\n",
    "        template: The template image of the feature.\n",
    "        rotation_angle: The angle by which the image was rotated (in degrees, clockwise).\n",
    "        image_center: The center of the rotation of the image.\n",
    "        scale_factor: Scaling factor for matching template size to image size\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The refined location (x, y) in the rotated image coordinates.\n",
    "            - The rotated initial location\n",
    "            - The original initial location\n",
    "        Returns (None, None, None) if template matching fails.\n",
    "    \"\"\"\n",
    "\n",
    "    chip_type = user_chip_mapping.get('chip_type')\n",
    "    rotation_angle = user_chip_mapping.get('rotation_angle', 0)\n",
    "    scale_factor = user_chip_mapping.get('scale_factor', 1.0)\n",
    "    image_center = (image.shape[1] / 2, image.shape[0] / 2)\n",
    "    user_features = user_chip_mapping.get('features', None)\n",
    "\n",
    "    if not user_features:\n",
    "        return None\n",
    "\n",
    "    for idx, f in enumerate(user_features):\n",
    "        label = f.get('label')\n",
    "        user_location = f.get('user_location')\n",
    "\n",
    "        # Rotate the user location to match the rotated image\n",
    "        rotated_user_location = rotate_user_feature_locations(user_location, image_center, rotation_angle)\n",
    "\n",
    "        # Load template image\n",
    "        template = get_template_image_from_label(chip_type, label)\n",
    "\n",
    "        # Scale template to match image size\n",
    "        template = scale_template(template, scale_factor)\n",
    "\n",
    "        # Define a search window around the rotated initial location\n",
    "        search_window_size = (template.shape[1] * 3, template.shape[0] * 3)\n",
    "        x_start = max(0, int(rotated_user_location[0] - search_window_size[0] / 2))\n",
    "        y_start = max(0, int(rotated_user_location[1] - search_window_size[1] / 2))\n",
    "        x_end = min(image.shape[1], int(rotated_user_location[0] + search_window_size[0] / 2))\n",
    "        y_end = min(image.shape[0], int(rotated_user_location[1] + search_window_size[1] / 2))\n",
    "\n",
    "        search_window = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(search_window, template, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        if max_val > 0.7:\n",
    "            refined_x = x_start + max_loc[0]\n",
    "            refined_y = y_start + max_loc[1]\n",
    "            user_chip_mapping['features'][idx]['refined_location'] = [refined_x, refined_y]\n",
    "        else:\n",
    "            user_chip_mapping['features'][idx]['refined_location'] = None\n",
    "\n",
    "    return user_chip_mapping, [refined_x, refined_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e1f2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User chip mapping: {'chip_type': 'IMECII_2', 'features': [{'label': 'D-Right', 'user_location': [1840, 849], 'chip_location': [2261, -1040], 'refined_location': [1821, 831]}, {'label': 'E-Right', 'user_location': [1848, 122], 'chip_location': [2261, -2040], 'refined_location': [1821, 106]}], 'user_location_angle': -89.36953543860086, 'chip_location_angle': -90.0, 'rotation_angle': -0.23587176756903716, 'scale_factor': 0.7270440151737719}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to perform image alignment and feature localization.\"\"\"\n",
    "# 1. Load data\n",
    "feature_location_json = Path('../config/FeatureLocation.json')\n",
    "chip_location_json = Path('../Label_templates/Chip_map_list.json')\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "image = cv2.normalize(\n",
    "        image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U # type: ignore\n",
    "    )  # Normalize to 8-bit range (0-255)\n",
    "if len(image.shape) > 2:  # Check if the image has more than one channel (i.e., it's not already greyscale)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "if image is None:\n",
    "    print(f\"Error: Could not load image from {image_path}\")\n",
    "    exit(1)\n",
    "\n",
    "user_chip_mapping = load_user_feature_locations(feature_location_json)\n",
    "user_chip_mapping = load_chip_feature_locations(chip_location_json, user_chip_mapping)\n",
    "user_chip_mapping, rotation_angle = user_chip_rotation_angle(user_chip_mapping)\n",
    "user_chip_mapping, scale_factor = user_chip_scale_factor(user_chip_mapping)\n",
    "\n",
    "# 2. Rotate image using user angle\n",
    "rotated_image = rotate_image(image, -rotation_angle)\n",
    "if rotated_image is None:\n",
    "    print(\"Error: Image rotation and scaling failed.\")\n",
    "    exit(1)\n",
    "\n",
    "# 3. Refine feature locations using template matching\n",
    "user_chip_mapping, refined_locations = refine_feature_locations(rotated_image, user_chip_mapping)\n",
    "\n",
    "# 4. Refine rotation angle now we've located the image features\n",
    "refined_f1 = user_chip_mapping['features'][0]['refined_location']\n",
    "refined_f2 = user_chip_mapping['features'][1]['refined_location']\n",
    "refined_angle = angle_between_points(refined_f1, refined_f2)\n",
    "\n",
    "chip_f1 = user_chip_mapping['features'][0]['chip_location']\n",
    "chip_f2 = user_chip_mapping['features'][1]['chip_location']\n",
    "map_angle = angle_between_points(chip_f1, chip_f2)\n",
    "\n",
    "refined_rotation_angle = map_angle - refined_angle\n",
    "user_chip_mapping['rotation_angle'] = rotation_angle + refined_rotation_angle\n",
    "\n",
    "# 5. Rotate image by refined rotation angle\n",
    "rotated_image = rotate_image(image, -user_chip_mapping['rotation_angle'])\n",
    "if rotated_image is None:\n",
    "    print(\"Error: Image rotation and scaling failed.\")\n",
    "    exit(1)\n",
    "\n",
    "# 6. Refine feature locations again with new rotation angle using template matching\n",
    "user_chip_mapping, refined_locations = refine_feature_locations(rotated_image, user_chip_mapping)\n",
    "\n",
    "# 6. Display results\n",
    "print(f'User chip mapping: {user_chip_mapping}')\n",
    "\n",
    "# Draw circles at the refined locations\n",
    "user_features = user_chip_mapping.get('features', None)\n",
    "for f in user_features:\n",
    "    label = f.get('label')\n",
    "    user_location = f.get('user_location')\n",
    "    cv2.circle(rotated_image, user_location, 5, (255, 255, 255), 2)\n",
    "    chip_location = f.get('chip_location')\n",
    "    cv2.circle(rotated_image, chip_location, 25, (255, 255, 255), 2)\n",
    "    refined_location = f.get('refined_location')\n",
    "    cv2.circle(rotated_image, refined_location, 10, (255, 255, 255), 2)\n",
    "cv2.imshow('Rotated Image with Refined Locations', rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
